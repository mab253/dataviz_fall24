{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t4G-itNXIXiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdhmIQKYDm4E",
        "outputId": "5d1c7ea5-6e2a-4337-cfbe-60ff6ac8e3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       County  Yes   No Total votes Percent of votes in % In\n",
            "0     Suffolk  54%  46%     692,860                     >95%\n",
            "1    Brooklyn  79%  21%     665,275                     >95%\n",
            "2      Nassau  55%  45%     628,488                     >95%\n",
            "3      Queens  74%  26%     586,360                      94%\n",
            "4   Manhattan  86%  14%     550,873                      80%\n",
            "..        ...  ...  ...         ...                      ...\n",
            "57     Seneca  48%  52%      14,327                     >95%\n",
            "58      Lewis  31%  69%      11,759                     >95%\n",
            "59      Yates  40%  60%      10,164                     >95%\n",
            "60   Schuyler  46%  54%       9,080                     >95%\n",
            "61   Hamilton  39%  61%       3,148                     >95%\n",
            "\n",
            "[62 rows x 5 columns]\n",
            "Data saved to /content/ballot_results.json\n"
          ]
        }
      ],
      "source": [
        "# first we get the unofficial election results:\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL of the NYT webpage containing the data\n",
        "url = 'https://www.nytimes.com/interactive/2024/11/05/us/elections/results-new-york-constitutional-amendment-1-equal-protection-of-law.html'  # Replace with the actual URL\n",
        "\n",
        "# send a GET request to the webpage\n",
        "response = requests.get(url)\n",
        "\n",
        "# 200 status code = YES, this went well ...\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # find the correct table (adjust selector as needed)\n",
        "    tables = soup.find_all('table', {'data-rid': 'NY-I-83165-NY-2024-11-05'})\n",
        "\n",
        "    if len(tables) >= 2:  # check if at least 2 such tables exist\n",
        "        table = tables[1]  # select the second table (it's the 2nd one on the page)\n",
        "\n",
        "    # extract rows\n",
        "    rows = []\n",
        "    # tr, td, th are all html tags: <tr> = table row, <td> = table cell ...\n",
        "    for row in table.find_all('tr'):\n",
        "        cells = row.find_all(['td', 'th'])  # het all cells\n",
        "        row_data = [cell.text.strip() for cell in cells]\n",
        "        if row_data:  # skip empty rows\n",
        "            rows.append(row_data)\n",
        "\n",
        "    # use the first row as headers and remaining rows as data\n",
        "    headers = rows[0]  # first row as column names\n",
        "    data = rows[1:]  # all other rows as data\n",
        "\n",
        "    data = data[:-1]\n",
        "    # chop off the last row, it was saying \"See fewer\" from the page\n",
        "\n",
        "    # create DataFrame\n",
        "    df = pd.DataFrame(data, columns=headers)\n",
        "\n",
        "    # display the DataFrame\n",
        "    print(df)\n",
        "\n",
        "    # save as JSON\n",
        "    json_file_path = '/content/ballot_results.json'  # Update path if needed\n",
        "    df.to_json(json_file_path, orient='records', indent=4)\n",
        "\n",
        "    print(f\"Data saved to {json_file_path}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGEd37ukJ96g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}